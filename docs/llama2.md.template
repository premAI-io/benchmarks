# ⚙️ Benchmarking ML Engines

## A100 80GB Inference Bench:

**Environment:**
- Model: Llama 2 7B Chat
- CUDA Version: 12.1
- Command: `./benchmark.sh --repetitions 10 --max_tokens 512 --device cuda --model llama --prompt 'Write an essay about the transformer model architecture'`

**Performance Metrics:** (unit: Tokens / second)

| Engine                                      | float32      | float16        | int8          | int4          |
|---------------------------------------------|--------------|----------------|---------------|---------------|
| [transformers (pytorch)](/bench_pytorch/)   | 36.65 ± 0.61 | 34.20 ± 0.51   | 6.91 ± 0.14   | 17.83 ± 0.40  |
| [AutoAWQ](/bench_autoawq/)                  |      -       |      -         |      -        | 63.59 ± 1.86  |
| [AutoGPTQ](/bench_autogptq/)                | 34.36 ± 0.51 | 36.63 ± 0.61   |               |               |
| [DeepSpeed](/bench_deepspeed/)              |              | 84.60 ± 0.25   |               |               |
| [ctransformers](/bench_ctransformers/)      |      -       |      -         | 85.50 ± 1.00  | 86.66 ± 1.06  |
| [llama.cpp](/bench_llamacpp/)               |      -       |      -         | 89.90 ± 2.26  | 97.35 ± 4.71  |
| [ctranslate](/bench_ctranslate/)            | 46.26 ± 1.59 | 79.41 ± 0.37   | 48.20 ± 0.14  |      -        |
| [vllm](/bench_vllm/)                        | 89.40 ± 0.22 | 89.43 ± 0.19   |      -        | 115.52 ± 0.49 |
| [exllamav2](/bench_exllamav2/)              |      -       |      -         | 125.58 ± 1.23 | 159.68 ± 1.85 |


**Performance Metrics:** GPU Memory Consumption (unit: MB)

| Engine                                      | float32  | float16  | int8     | int4     |
|---------------------------------------------|----------|----------|----------|----------|
| [transformers (pytorch)](/bench_pytorch/)   | 29114.76 | 14931.72 | 8596.23  | 5643.44  |
| [AutoAWQ](/bench_autoawq/)                  |      -   |      -   |      -   | 7149.19  |
| [AutoGPTQ](/bench_autogptq/)                | 10718.54 | 5706.35  |          |          |
| [DeepSpeed](/bench_deepspeed/)              |          | 83978.35 |          |          |
| [ctransformers](/bench_ctransformers/)      |      -   |      -   | 9774.83  | 6889.14  |
| [llama.cpp](/bench_llamacpp/)               |      -   |      -   | 8797.55  | 5783.95  |
| [ctranslate](/bench_ctranslate/)            | 29951.52 | 16282.29 | 9470.74  |      -   |
| [vllm](/bench_vllm/)                        | 77928.07 | 77928.07 |      -   | 77768.69 |
| [exllamav2](/bench_exllamav2/)              |      -   |      -   | 16582.18 | 7201.62  |

*(Data updated: `<LAST_UPDATE>`)


## M2 MAX 32GB Inference Bench:

### CPU

**Environment:**
- Model: LLAMA-2-7B
- CUDA Version: NA
- Command: `./benchmark.sh --repetitions 10 --max_tokens 512 --device cpu --prompt 'Write an essay about the transformer model architecture'`

**Performance Metrics:** (unit: Tokens / second)
| Engine                                 | float32      | float16      | int8         | int4         |
|----------------------------------------|--------------|--------------|--------------|--------------|
| [candle](/bench_candle/)               |      -       | 3.43 ± 0.02  |      -       |      -       |
| [llama.cpp](/bench_llamacpp/)          |      -       |      -       | 13.24 ± 0.62 | 21.43 ± 0.47 |
| [ctranslate](/bench_ctranslate/)       |      -       |      -       | 1.87 ± 0.14  |      -       |
| [ctransformers](/bench_ctransformers/) |      -       |      -       | 13.50 ± 0.48 | 20.57 ± 2.50 |


### GPU (Metal)

**Command:** `./benchmark.sh --repetitions 10 --max_tokens 512 --device metal --prompt 'Write an essay about the transformer model architecture'`

**Performance Metrics:** (unit: Tokens / second)
| Engine                                  | float32      | float16       | int8         | int4         |
|-----------------------------------------|--------------|---------------|--------------|--------------|
| [llama.cpp](/bench_llamacpp/)           |      -       |      -        | 30.11 ± 0.45 | 44.27 ± 0.12 |
| [ctransformers](/bench_ctransformers/)  |      -       |      -        | 20.75 ± 0.36 | 34.04 ± 2.11 |

*(Data updated: `<LAST_UPDATE>`)
