# ⚙️ Benchmarking ML Engines

## A100 80GB Inference Bench:

**Environment:**
- Model: Mistral 7B v0.1 Instruct
- CUDA Version: 12.1
- Command: `./benchmark.sh --repetitions 10 --max_tokens 512 --device cuda --model mistral --prompt 'Write an essay about the transformer model architecture'`

**Performance Metrics:** (unit: Tokens / second)

| Engine                                      | float32      | float16        | int8          | int4          |
|---------------------------------------------|--------------|----------------|---------------|---------------|
| [transformers (pytorch)](/bench_pytorch/)   | 39.61 ± 0.65 | 37.05 ± 0.49   | 5.08 ± 0.01   | 19.58 ± 0.38  |
| [AutoAWQ](/bench_autoawq/)                  |      -       |      -         |      -        | 63.12 ± 2.19  |
| [AutoGPTQ](/bench_autogptq/)                | 39.11 ± 0.42 | 42.94 ± 0.80   |               |               |
| [DeepSpeed](/bench_deepspeed/)              |              | 79.88 ± 0.32   |               |               |
| [ctransformers](/bench_ctransformers/)      |      -       |      -         | 86.14 ± 1.40  | 87.22 ± 1.54  |
| [llama.cpp](/bench_llamacpp/)               |      -       |      -         | 88.27 ± 0.72  | 95.33 ± 5.54  |
| [ctranslate](/bench_ctranslate/)            | 43.17 ± 2.97 | 68.03 ± 0.27   | 45.14 ± 0.24  |      -        |

**Performance Metrics:** GPU Memory Consumption (unit: MB)

| Engine                                      | float32  | float16  | int8     | int4     |
|---------------------------------------------|----------|----------|----------|----------|
| [transformers (pytorch)](/bench_pytorch/)   | 31071.4  | 15976.1  | 10963.91 | 5681.18  |
| [AutoGPTQ](/bench_autogptq/)                | 13400.80 | 6633.29  |          |          |
| [AutoAWQ](/bench_autoawq/)                  |      -   |      -   |      -   | 6572.47  |
| [DeepSpeed](/bench_deepspeed/)              |          | 80104.34 |          |          |
| [ctransformers](/bench_ctransformers/)      |      -   |      -   | 10255.07 | 6966.74  |
| [llama.cpp](/bench_llamacpp/)               |      -   |      -   | 9141.49  | 5880.41  |
| [ctranslate](/bench_ctranslate/)            | 32602.32 |  17523.8 | 10074.72 |      -   |


*(Data updated: `<LAST_UPDATE>`)
