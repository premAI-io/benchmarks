# ⚙️ Benchmarking ML Engines

## A100 80GB Inference Bench:

**Environment:**
- Model: Mistral 7B v0.1 Instruct
- CUDA Version: 12.1
- Command: `./benchmark.sh --repetitions 10 --max_tokens 512 --device cuda --model mistral --prompt 'Write an essay about the transformer model architecture'`

**Performance Metrics:** (unit: Tokens / second)

| Engine                                      | float32      | float16        | int8          | int4          |
|---------------------------------------------|--------------|----------------|---------------|---------------|
| [transformers (pytorch)](/bench_pytorch/)   | 39.27 ± 0.54 | 37.57 ± 0.36   | 5.03 ± 0.08   | 19.70 ± 0.30  |

**Performance Metrics:** GPU Memory Consumption (unit: MB)

| Engine                                      | float32  | float16  | int8     | int4     |
|---------------------------------------------|----------|----------|----------|----------|
| [transformers (pytorch)](/bench_pytorch/)   | 31069.31 | 46030.39 | 23957.86 | 13935.58 |


*(Data updated: `<LAST_UPDATE>`)
